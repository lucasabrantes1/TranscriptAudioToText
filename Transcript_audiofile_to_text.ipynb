{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install vosk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyspellchecker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vosk model languange download\n",
    "#https://alphacephei.com/vosk/models\n",
    "#portuguese: https://alphacephei.com/vosk/models/vosk-model-pt-fb-v0.1.1-20220516_2113.zip\n",
    "#portuguese small: https://alphacephei.com/vosk/models/vosk-model-small-pt-0.3.zip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "\n",
    "r = sr.Recognizer()\n",
    "with sr.AudioFile(r'C:\\Users\\PC\\Downloads\\file.wav') as source:\n",
    "    audio_data = r.record(source)\n",
    "    \n",
    "    try:\n",
    "        text = r.recognize_google(audio_data, language='pt-BR')\n",
    "        print(\"Transcrição: \", text)\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Google Speech Recognition não conseguiu entender o áudio\")\n",
    "    except sr.RequestError as e:\n",
    "        print(f\"Não foi possível solicitar resultados do serviço Google Speech Recognition; {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcripted default with spellcheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "# Função para corrigir texto\n",
    "def corrigir_texto(texto):\n",
    "    spell = SpellChecker(language='pt')\n",
    "    palavras = texto.split()\n",
    "    palavras_corrigidas = [spell.correction(palavra) for palavra in palavras]\n",
    "    texto_corrigido = ' '.join(palavras_corrigidas)\n",
    "    return texto_corrigido\n",
    "\n",
    "# Instancia o reconhecedor\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# Carrega o arquivo de áudio\n",
    "with sr.AudioFile(r'C:\\Users\\PC\\Downloads\\file.wav') as source:\n",
    "    audio_data = r.record(source)\n",
    "\n",
    "    # Tenta transcrever o áudio para texto\n",
    "    try:\n",
    "        texto_transcrito = r.recognize_google(audio_data, language='pt-BR')\n",
    "        print(\"Transcrição Original: \", texto_transcrito)\n",
    "        \n",
    "        # Corrige o texto transcrito\n",
    "        texto_corrigido = corrigir_texto(texto_transcrito)\n",
    "        print(\"Transcrição Corrigida: \", texto_corrigido)\n",
    "        \n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Google Speech Recognition não conseguiu entender o áudio\")\n",
    "    except sr.RequestError as e:\n",
    "        print(f\"Não foi possível solicitar resultados do serviço Google Speech Recognition; {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcribe and correct the text method 1 with textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "from textblob import TextBlob\n",
    "\n",
    "def corrigir_texto(texto):\n",
    "    texto_corrigido = TextBlob(texto)\n",
    "    return texto_corrigido.correct()\n",
    "\n",
    "def transcrever_e_corrigir(caminho_do_arquivo):\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(caminho_do_arquivo) as source:\n",
    "        audio_data = r.record(source)\n",
    "        \n",
    "        try:\n",
    "            texto_transcrito = r.recognize_google(audio_data, language='pt-BR')\n",
    "            print(\"Transcrição Original: \", texto_transcrito)\n",
    "            \n",
    "            texto_corrigido = corrigir_texto(texto_transcrito)\n",
    "            print(\"Transcrição Corrigida: \", texto_corrigido)\n",
    "            \n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Google Speech Recognition não conseguiu entender o áudio\")\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"Não foi possível solicitar resultados do serviço Google Speech Recognition; {e}\")\n",
    "\n",
    "# Substitua 'caminho_para_seu_arquivo_de_audio.wav' pelo caminho real do seu arquivo de áudio\n",
    "caminho_do_arquivo = r'C:\\Users\\PC\\Downloads\\file.wav'\n",
    "transcrever_e_corrigir(caminho_do_arquivo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcribe and correct the text method 2 with model vosk textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vosk import Model, KaldiRecognizer\n",
    "import wave\n",
    "import json\n",
    "import os\n",
    "\n",
    "def transcrever_vosk(caminho_do_arquivo, caminho_do_modelo='modelo_vosk/'):\n",
    "    if not os.path.exists(caminho_do_modelo):\n",
    "        print(\"Modelo Vosk não encontrado em:\", caminho_do_modelo)\n",
    "        return\n",
    "\n",
    "    # Carregar o modelo Vosk\n",
    "    model = Model(caminho_do_modelo)\n",
    "    rec = KaldiRecognizer(model, 16000)\n",
    "\n",
    "    # Abrir o arquivo de áudio com wave\n",
    "    try:\n",
    "        with wave.open(caminho_do_arquivo, \"rb\") as wf:\n",
    "            # Configurar o reconhecedor com a taxa de amostragem do arquivo\n",
    "            rec = KaldiRecognizer(model, wf.getframerate())\n",
    "            rec.SetWords(True)  # Para obter a saída com palavras reconhecidas\n",
    "            texto_transcrito = \"\"\n",
    "\n",
    "            # Processar o arquivo de áudio e obter a transcrição\n",
    "            while True:\n",
    "                data = wf.readframes(4000)\n",
    "                if len(data) == 0:\n",
    "                    break\n",
    "                if rec.AcceptWaveform(data):\n",
    "                    partial_result = json.loads(rec.Result())\n",
    "                    texto_transcrito += partial_result.get('text', '') + \" \"\n",
    "            \n",
    "            # Obter resultados finais\n",
    "            final_result = json.loads(rec.FinalResult())\n",
    "            texto_transcrito += final_result.get('text', '')\n",
    "\n",
    "            print(\"Transcrição Original: \", texto_transcrito)\n",
    "    except wave.Error as e:\n",
    "        print(\"Erro ao abrir o arquivo de áudio:\", e)\n",
    "    except Exception as e:\n",
    "        print(\"Erro durante a transcrição:\", e)\n",
    "\n",
    "# Substitua os caminhos abaixo conforme necessário\n",
    "caminho_do_arquivo = r'C:\\Users\\PC\\Downloads\\file.wav'\n",
    "caminho_do_modelo = r'C:\\Users\\PC\\Documents\\vosk-model-small-pt-0.3'\n",
    "transcrever_vosk(caminho_do_arquivo, caminho_do_modelo)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
